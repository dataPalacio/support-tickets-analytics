# ğŸ“Š Projeto AnÃ¡lise de Tickets de Suporte TÃ©cnico

Este projeto foi criado para resolver um problema comum enfrentado pelo Ã³rgÃ£o pÃºblico: **a dificuldade em extrair informaÃ§Ãµes relevantes e confiÃ¡veis a partir dos dados brutos dos tickets de suporte tÃ©cnico**. Muitas vezes, esses dados vÃªm em formatos variados, com inconsistÃªncias e informaÃ§Ãµes incompletas, o que dificulta anÃ¡lises precisas.

O objetivo principal aqui Ã© implementar um pipeline que faÃ§a a limpeza, organizaÃ§Ã£o e enriquecimento desses dados, transformando-os em um formato estruturado e de fÃ¡cil consulta. Isso permite que gestores e analistas possam obter insights valiosos para melhorar a eficiÃªncia do suporte, identificar gargalos e priorizar aÃ§Ãµes corretivas.

---

## ğŸ“¦ Como clonar o projeto

```bash
git clone https://github.com/seu-usuario/seu-repositorio.git
cd seu-repositorio
```

> Copie o link do projeto: https://github.com/dataPalacio/support-tickets-analytics.git

---

## ğŸ§± Estrutura do Projeto

```
ğŸ“ support-tickets-analytics/
â”œâ”€â”€ ğŸ“‚ data/            # Dados brutos e processados (CSV, Excel, etc.)
â”‚   â”œâ”€â”€ ğŸ“‚ raw/         # Dados brutos originais
â”‚   â””â”€â”€ ğŸ“‚ processed/   # Dados processados
â”œâ”€â”€ ğŸ“‚ scripts/         # Scripts Python (ETL, processamento, etc.)
â”œâ”€â”€ ğŸ“‚ notebooks/       # Notebooks exploratÃ³rios (.ipynb)
â”œâ”€â”€ ğŸ“‚ dashboards/      # Dashboards Power BI (.pbix) e mockups
â”œâ”€â”€ ğŸ“‚ reports/         # RelatÃ³rios finais e figuras geradas
â”œâ”€â”€ ğŸ“‚ docs/            # DocumentaÃ§Ã£o adicional (PDFs, imagens, manuais)
â”œâ”€â”€ requirements.txt    # DependÃªncias do projeto
â”œâ”€â”€ README.md           # DescriÃ§Ã£o geral do projeto
â””â”€â”€ .gitignore
```

- **`data/`**: arquivos brutos, tratados e externos.
- **`scripts/`**: scripts de processamento, como `main.py`.
- **`notebooks/`**: notebooks exploratÃ³rios e anÃ¡lises estatÃ­sticas.
- **`dashboards/`**: arquivos .pbix do Power BI e mockups.
- **`reports/`**: relatÃ³rios finais e figuras geradas.
- **`docs/`**: documentaÃ§Ã£o complementar, imagens ou relatÃ³rios.

---

## ğŸš€ O que esse cÃ³digo faz?

1. **Carrega os dados** de um arquivo `.csv` ou `.xlsx`.
2. **Padroniza os nomes das colunas** (tira acento, deixa tudo minÃºsculo).
3. **Limpa os campos** (remove espaÃ§os, formata datas, etc).
4. **Atribui responsÃ¡veis** com base na localizaÃ§Ã£o.
5. **Filtra sÃ³ o que importa** (colunas relevantes).
6. **Extrai o nome do equipamento** do tÃ­tulo da solicitaÃ§Ã£o.
7. **(Opcional)** Salva o resultado em um novo `.csv`.

---

## ğŸ› ï¸ Como executar


```python
from scripts.main import exec_pipeline

df_final = exec_pipeline("data/arquivo.csv", save_csv="output/saida.csv")
```

Se quiser sÃ³ ver o resultado sem salvar, Ã© sÃ³ nÃ£o passar o `save_csv`.

---

## ğŸš€ O que o pipeline entrega?

- Carrega e padroniza dados de arquivos `.csv` ou `.xlsx`.
- Limpa campos, formata datas e padroniza nomes de colunas.
- Atribui responsÃ¡veis automaticamente com base na localizaÃ§Ã£o.
- Filtra apenas as colunas relevantes e extrai o nome do equipamento do tÃ­tulo.
- Gera um DataFrame limpo, padronizado e enriquecido, pronto para anÃ¡lise, visualizaÃ§Ãµes, dashboards ou relatÃ³rios.
- (Opcional) Salva o resultado em um novo `.csv`.

---


## ğŸ“ Exemplo de colunas esperadas

- `ID`
- `TÃ­tulo`
- `Data de abertura`
- `Requerente - Requerente`
- `LocalizaÃ§Ã£o`
- `Equipamento Quantidade`
- `AtribuÃ­do - Grupo tÃ©cnico`
- `Status`
- `Data de fechamento`
- `Contato`
- `Feedback`

---


## âœ… Exemplo de resultado

O pipeline gera um DataFrame com as seguintes colunas padronizadas:

- `id`, `titulo`, `data_abertura`, `requerente`, `localizacao`, `g_responsavel`, `status`, `data_fechamento`, `contato`, `feedback`, `equipamento_qtd`, `responsavel`, `equipamento`

**ObservaÃ§Ãµes:**
- A coluna `responsavel` Ã© criada automaticamente pelo pipeline, com base na localizaÃ§Ã£o (`localizacao`).
- A coluna `equipamento` Ã© extraÃ­da do campo `titulo` quando o padrÃ£o "SolicitaÃ§Ã£o de equipamento - ..." Ã© encontrado.
- `g_responsavel` corresponde ao grupo tÃ©cnico original do chamado.
- Colunas nÃ£o listadas acima sÃ£o descartadas durante o processamento.

### Exemplo de entrada e saÃ­da

**Linha de entrada (CSV):**

```
ID;TÃ­tulo;Equipamento Quantidade;Data de abertura;Requerente - Requerente;LocalizaÃ§Ã£o;AtribuÃ­do - Grupo tÃ©cnico;Status;Data de fechamento;Contato;Feedback
30128;SolicitaÃ§Ã£o de equipamento - Computador;3;01/07/2025;user_006;LOC_001; Suporte N2;Estoque;22/07/2025;Sistema;
```

**Linha processada (DataFrame):**

| id    | titulo                           | data_abertura | requerente | localizacao | g_responsavel | status  | data_fechamento | contato | feedback | equipamento_qtd | responsavel | equipamento |
|-------|-----------------------------------|---------------|------------|-------------|---------------|---------|-----------------|---------|----------|-----------------|-------------|-------------|
|30128  |SolicitaÃ§Ã£o de equipamento - Computador|2025-07-01    |USER_006    |LOC_001      |Suporte N2     |Estoque  |2025-07-22       |Sistema  |          |3                |InformÃ¡tica  |Computador   |

**AtenÃ§Ã£o:**
- O pipeline espera que os nomes das colunas no CSV de entrada estejam exatamente como listados em "Exemplo de colunas esperadas" (com acentos e maiÃºsculas/minÃºsculas corretos). Internamente, todos os nomes sÃ£o padronizados para minÃºsculo e sem acento.

---

## ğŸ” O que podemos retirar desse projeto?

- Um **DataFrame limpo e padronizado**, pronto para anÃ¡lise.
- InformaÃ§Ãµes enriquecidas com **responsÃ¡veis atribuÃ­dos automaticamente**.
- ExtraÃ§Ã£o de **nomes de equipamentos** a partir de descriÃ§Ãµes.
- Dados prontos para **visualizaÃ§Ãµes, dashboards ou relatÃ³rios**.

---

## â“ Quais perguntas de negÃ³cio podemos resolver?

- Quais sÃ£o os **equipamentos mais solicitados**?
- Quais **localizaÃ§Ãµes** geram mais demandas?
- Quem sÃ£o os **responsÃ¡veis mais acionados**?
- Existe sazonalidade nas **datas de abertura** dos chamados?
- Quais **requerentes** mais solicitam equipamentos?
- HÃ¡ locais com **sobrecarga de solicitaÃ§Ãµes**?

---

## ğŸ›  Tecnologias Utilizadas
- **Python** (Bibliotecas: pandas, os, re, numpy, unicodedata)
- **VS Code + Data_Wrangler** para anÃ¡lises e visualizaÃ§Ãµes interativas
- **GitHub** para versionamento e compartilhamento do projeto


---

## ğŸ”® AnÃ¡lises PossÃ­veis a Serem Acrescentadas

- ğŸ“Š **GrÃ¡ficos de tendÃªncia** por mÃªs ou trimestre.
- ğŸ—ºï¸ **Mapeamento geogrÃ¡fico** das localizaÃ§Ãµes (se houver coordenadas).
- ğŸ“ˆ **Dashboards interativos** com ferramentas como Power BI ou Plotly.
- â±ï¸ **Tempo mÃ©dio de atendimento** (se houver data de fechamento).
- ğŸ§  **ClassificaÃ§Ã£o automÃ¡tica** de solicitaÃ§Ãµes por tipo.
- ğŸ“Œ **ClusterizaÃ§Ã£o** de localizaÃ§Ãµes com padrÃµes semelhantes.

---
## ğŸ“„ LicenÃ§a

Todos os projetos neste repositÃ³rio estÃ£o sob a LicenÃ§a MIT.

## ConsideraÃ§Ãµes Finais

Desenvolvido com â¤ï¸ por [Gustavo Palacio](https://www.linkedin.com/in/gfpalacio/).

Feito pra facilitar a vida de quem analisa dados de chamados e quer tudo pronto pra usar. Qualquer dÃºvida ou melhoria, sÃ³ chamar! ğŸ˜„

ğŸ“Œ **Autor:** *Gustavo Palacio*  
ğŸ“… **Data:** *Julho de 2025*
